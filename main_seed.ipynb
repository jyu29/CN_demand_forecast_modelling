{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aquatic-plymouth",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import src.utils as ut\n",
    "from src.data_handler import data_handler\n",
    "from src.sagemaker_utils import generate_df_jobs, SagemakerHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-haven",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cutoff = [202109]\n",
    "run_name = 'test'\n",
    "environment = 'seed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-opportunity",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = ut.import_raw_config(environment)\n",
    "\n",
    "global_bucket = confs['buckets']['refined_data_global']\n",
    "global_path = confs['paths']['refined_global_path']\n",
    "\n",
    "specific_bucket = confs['buckets']['refined_data_specific']\n",
    "specific_path = confs['paths']['refined_specific_path']\n",
    "\n",
    "algorithm = ut.import_raw_config(environment)['modeling_parameters']['algorithm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-pipeline",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_week_sales = ut.read_multipart_parquet_s3(global_bucket, global_path + 'model_week_sales')\n",
    "df_model_week_tree = ut.read_multipart_parquet_s3(global_bucket, global_path + 'model_week_tree')\n",
    "df_model_week_mrp = ut.read_multipart_parquet_s3(global_bucket, global_path + 'model_week_mrp')\n",
    "df_imputed_sales_lockdown_1 = ut.read_multipart_parquet_s3('fcst-refined-demand-forecast-dev', \n",
    "                                                           global_path + 'imputed_sales_lockdown_1.parquet')\n",
    "\n",
    "df_store_openings = pd.read_csv('data/store_openings.csv')\n",
    "df_holidays = pd.read_csv('data/holidays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "if confs['refining_specific_parameters']['patch_first_lockdown']:\n",
    "    print(\"True\")\n",
    "    df_store_openings.loc[df_store_openings['week_id'].between(202011, 202028), 'perc_store_closed'] = 0\n",
    "    df_store_openings.loc[df_store_openings['week_id'].between(202011, 202028), 'perc_store_partially_closed'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-cannon",
   "metadata": {},
   "source": [
    "## Generate df_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data_specific_path = ut.to_uri(specific_bucket, specific_path)\n",
    "\n",
    "df_jobs = generate_df_jobs(list_cutoff=list_cutoff,\n",
    "                           run_name=run_name,\n",
    "                           algorithm=algorithm,\n",
    "                           refined_data_specific_path=refined_data_specific_path\n",
    "                           )\n",
    "df_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-accommodation",
   "metadata": {},
   "source": [
    "## Generate modeling specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in list_cutoff:\n",
    "    \n",
    "    print(cutoff)\n",
    "    \n",
    "    # Base data\n",
    "    base_data = {\n",
    "        'model_week_sales': df_model_week_sales,\n",
    "        'model_week_tree': df_model_week_tree,\n",
    "        'model_week_mrp': df_model_week_mrp,\n",
    "        'imputed_sales_lockdown_1': df_imputed_sales_lockdown_1\n",
    "    }\n",
    "    \n",
    "    # Static features\n",
    "    df_static_tree = df_model_week_tree[df_model_week_tree['week_id'] == cutoff].copy()\n",
    "    \n",
    "    static_features = {\n",
    "        'model_identifier': pd.DataFrame({'model_id': df_static_tree['model_id'],\n",
    "                                          'model_identifier': df_static_tree['model_id']}),\n",
    "        'family_id': df_static_tree[['model_id', 'family_id']],\n",
    "        'sub_department_id': df_static_tree[['model_id', 'sub_department_id']],\n",
    "        'department_id': df_static_tree[['model_id', 'department_id']],\n",
    "        'univers_id': df_static_tree[['model_id', 'univers_id']],\n",
    "        'product_nature_id': df_static_tree[['model_id', 'product_nature_id']]\n",
    "    }\n",
    "    \n",
    "    # Dynamic features\n",
    "    global_dynamic_features = {\n",
    "        'perc_store_closed': {'dataset': df_store_openings[['week_id', 'perc_store_closed']], \n",
    "                              'projection': 'as_provided'},\n",
    "        'perc_store_partially_closed': {'dataset': df_store_openings[['week_id', 'perc_store_partially_closed']], \n",
    "                                        'projection': 'as_provided'},\n",
    "        'holidays': {'dataset': df_holidays, 'projection': 'as_provided'}\n",
    "    }\n",
    "\n",
    "    specific_dynamic_features = None\n",
    "    \n",
    "    # Import refining config\n",
    "    train_path = df_jobs[df_jobs['cutoff'] == cutoff].loc[:, 'train_path'].values[0]\n",
    "    predict_path = df_jobs[df_jobs['cutoff'] == cutoff].loc[:, 'predict_path'].values[0]\n",
    "\n",
    "    refining_params = ut.import_refining_config(\n",
    "        environment=environment,\n",
    "        cutoff=cutoff,\n",
    "        run_name=run_name,\n",
    "        train_path=train_path,\n",
    "        predict_path=predict_path\n",
    "    )\n",
    "\n",
    "    dh = data_handler(\n",
    "        base_data=base_data,\n",
    "        static_features=static_features,\n",
    "        global_dynamic_features=global_dynamic_features,\n",
    "        specific_dynamic_features=specific_dynamic_features,\n",
    "        **refining_params\n",
    "    )\n",
    "\n",
    "    dh.execute_data_refining_specific()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free some memory\n",
    "import gc\n",
    "del(df_model_week_sales, df_model_week_tree, df_model_week_mrp, df_store_openings, df_holidays)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-elite",
   "metadata": {},
   "source": [
    "## Launch parallel Fit-Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_params = ut.import_sagemaker_params(environment=environment)\n",
    "\n",
    "sh = SagemakerHandler(\n",
    "    run_name=run_name,\n",
    "    df_jobs=df_jobs,\n",
    "    **sagemaker_params\n",
    ")\n",
    "\n",
    "sh.launch_training_jobs()\n",
    "\n",
    "sh.launch_transform_jobs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pov_demand",
   "language": "python",
   "name": "conda_pov_demand"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
