{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c23011",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55cedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import src.data_handler as dh\n",
    "import src.sagemaker_utils as su\n",
    "import src.outputs_stacking as osk\n",
    "import src.utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58611557",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380058f3",
   "metadata": {},
   "source": [
    "#### Modeling arguments handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENVIRONMENT = 'seed'\n",
    "LIST_CUTOFF = [202050, 202051, 202052, 202053, 202101, 202102, 202103, 202104, 202105, 202106, 202107, 202108, \n",
    "               202109, 202110, 202111, 202112, 202113, 202114, 202115, 202116, 202117, 202118, 202119, 202120, \n",
    "               202121, 202122, 202123, 202124, 202125, 202126, 202127, 202128, 202129, 202130, 202131, 202132, \n",
    "               202133, 202134, 202135, 202136, 202137]\n",
    "LIST_CUTOFF = [202050]\n",
    "RUN_NAME = 'forecast-v21-debug'\n",
    "ut.check_environment(ENVIRONMENT)\n",
    "list_cutoff = ut.check_list_cutoff(LIST_CUTOFF)\n",
    "ut.check_run_name(RUN_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46c004",
   "metadata": {},
   "source": [
    "#### Logging level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a02f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGING_LVL = 'INFO'\n",
    "assert LOGGING_LVL in ['CRITICAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG'], 'Wrong logging level'\n",
    "for module in [dh, su, osk]:\n",
    "    module.logger.setLevel(LOGGING_LVL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f36d52",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_params = ut.import_modeling_parameters(ENVIRONMENT)\n",
    "\n",
    "REFINED_DATA_GLOBAL_BUCKET = main_params['refined_data_global_bucket']\n",
    "REFINED_DATA_SPECIFIC_BUCKET = main_params['refined_data_specific_bucket']\n",
    "REFINED_DATA_GLOBAL_PATH = main_params['refined_global_path']\n",
    "REFINED_DATA_SPECIFIC_PATH = main_params['refined_specific_path']\n",
    "REFINED_DATA_SPECIFIC_URI = ut.to_uri(REFINED_DATA_SPECIFIC_BUCKET, REFINED_DATA_SPECIFIC_PATH)\n",
    "\n",
    "MODEL_WEEK_SALES_PATH = f\"{REFINED_DATA_GLOBAL_PATH}model_week_sales\"\n",
    "MODEL_WEEK_TREE_PATH = f\"{REFINED_DATA_GLOBAL_PATH}model_week_tree\"\n",
    "MODEL_WEEK_MRP_PATH = f\"{REFINED_DATA_GLOBAL_PATH}model_week_mrp\"\n",
    "IMPUTED_SALES_LOCKDOWN_1_PATH = f\"{REFINED_DATA_GLOBAL_PATH}imputed_sales_lockdown_1.parquet\"\n",
    "\n",
    "LIST_ALGORITHM = list(main_params['algorithm'])\n",
    "OUTPUTS_STACKING = main_params['outputs_stacking']\n",
    "SHORT_TERM_ALGORITHM = main_params['short_term_algorithm']\n",
    "LONG_TERM_ALGORITHM = main_params['long_term_algorithm']\n",
    "SMOOTH_STACKING_RANGE = main_params['smooth_stacking_range']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4827f3",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7185d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_week_sales = ut.read_multipart_parquet_s3(REFINED_DATA_GLOBAL_BUCKET, MODEL_WEEK_SALES_PATH)\n",
    "df_model_week_tree = ut.read_multipart_parquet_s3(REFINED_DATA_GLOBAL_BUCKET, MODEL_WEEK_TREE_PATH)\n",
    "df_model_week_mrp = ut.read_multipart_parquet_s3(REFINED_DATA_GLOBAL_BUCKET, MODEL_WEEK_MRP_PATH)\n",
    "df_imputed_sales_lockdown_1 = ut.read_multipart_parquet_s3(REFINED_DATA_GLOBAL_BUCKET, IMPUTED_SALES_LOCKDOWN_1_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70311766",
   "metadata": {},
   "source": [
    "# Initialize df_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = su.generate_df_jobs(list_cutoff=list_cutoff,\n",
    "                              run_name=RUN_NAME,\n",
    "                              list_algorithm=LIST_ALGORITHM,\n",
    "                              refined_data_specific_path=REFINED_DATA_SPECIFIC_URI\n",
    "                              )\n",
    "df_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263b72ee",
   "metadata": {},
   "source": [
    "# Generate modeling specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1536291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _, job in df_jobs.iterrows():\n",
    "\n",
    "    # Parameters init\n",
    "    algorithm = job['algorithm']\n",
    "    cutoff = job['cutoff']\n",
    "    train_path = job['train_path']\n",
    "    predict_path = job['predict_path']\n",
    "\n",
    "    refining_params = dh.import_refining_config(environment=ENVIRONMENT,\n",
    "                                                algorithm=algorithm,\n",
    "                                                cutoff=cutoff,\n",
    "                                                train_path=train_path,\n",
    "                                                predict_path=predict_path\n",
    "                                                )\n",
    "\n",
    "    # Data/Features init\n",
    "    base_data = {\n",
    "        'model_week_sales': df_model_week_sales,\n",
    "        'model_week_tree': df_model_week_tree,\n",
    "        'model_week_mrp': df_model_week_mrp,\n",
    "        'imputed_sales_lockdown_1': df_imputed_sales_lockdown_1\n",
    "    }\n",
    "\n",
    "    if algorithm == 'deepar':\n",
    "        df_static_tree = df_model_week_tree[df_model_week_tree['week_id'] == cutoff].copy()\n",
    "\n",
    "        static_features = {\n",
    "            'family_id': df_static_tree[['model_id', 'family_id']],\n",
    "            'sub_department_id': df_static_tree[['model_id', 'sub_department_id']],\n",
    "            'department_id': df_static_tree[['model_id', 'department_id']],\n",
    "            'univers_id': df_static_tree[['model_id', 'univers_id']],\n",
    "            'product_nature_id': df_static_tree[['model_id', 'product_nature_id']]\n",
    "        }\n",
    "    else:\n",
    "        static_features = None\n",
    "    \n",
    "    global_dynamic_features = None\n",
    "\n",
    "    specific_dynamic_features = None\n",
    "\n",
    "    # Execute data refining\n",
    "    refining_handler = dh.DataHandler(base_data=base_data,\n",
    "                                      static_features=static_features,\n",
    "                                      global_dynamic_features=global_dynamic_features,\n",
    "                                      specific_dynamic_features=specific_dynamic_features,\n",
    "                                      **refining_params\n",
    "                                      )\n",
    "\n",
    "    refining_handler.execute_data_refining_specific()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656dc96",
   "metadata": {},
   "source": [
    "## Launch Fit & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fac9a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for algorithm in LIST_ALGORITHM:\n",
    "\n",
    "    df_jobs_algo = df_jobs[df_jobs['algorithm'] == algorithm].copy()\n",
    "\n",
    "    sagemaker_params = su.import_sagemaker_params(environment=ENVIRONMENT, algorithm=algorithm)\n",
    "\n",
    "    modeling_handler = su.SagemakerHandler(df_jobs=df_jobs_algo, **sagemaker_params)\n",
    "\n",
    "    modeling_handler.launch_training_jobs()\n",
    "\n",
    "    if algorithm == 'deepar':\n",
    "        modeling_handler.launch_transform_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65beea5",
   "metadata": {},
   "source": [
    "# Calculate outputs stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcddf09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORARY : Create fake df_jobs including old deepar run\n",
    "import boto3\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "def get_predict_json(cutoff):\n",
    "    if cutoff <= 202120:\n",
    "        all_objects = s3.list_objects(Bucket='fcst-refined-demand-forecast-prod',\n",
    "                                      Prefix=f'specific/forecast-v2-init/forecast-v2-init-deepar-{cutoff}/input/predict')\n",
    "    else:\n",
    "        all_objects = s3.list_objects(Bucket='fcst-refined-demand-forecast-prod',\n",
    "                                      Prefix=f'specific/sunday-pipeline/sunday-pipeline-deepar-{cutoff}/input/predict')\n",
    "    return all_objects['Contents'][0]['Key']\n",
    "\n",
    "df_jobs_deepar = pd.DataFrame({'cutoff' : df_jobs['cutoff']})\n",
    "df_jobs_deepar['algorithm'] = 'deepar'\n",
    "df_jobs_deepar['predict_path'] = \\\n",
    "    [f's3://fcst-refined-demand-forecast-prod/{get_predict_json(cutoff)}' for cutoff in df_jobs_deepar['cutoff']]\n",
    "\n",
    "df_jobs_tmp = df_jobs.append(df_jobs_deepar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08155a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_jobs_tmp.to_csv('df_jobs_tmp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b067d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_jobs = pd.read_csv(\"df_jobs_tmp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c9bfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if OUTPUTS_STACKING:\n",
    "    osk.calculate_outputs_stacking(\n",
    "        #df_jobs,\n",
    "        df_jobs_tmp,\n",
    "        short_term_algorithm=SHORT_TERM_ALGORITHM,\n",
    "        long_term_algorithm=LONG_TERM_ALGORITHM,\n",
    "        smooth_stacking_range=SMOOTH_STACKING_RANGE\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_forecast-modeling-demand",
   "language": "python",
   "name": "conda_forecast-modeling-demand"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
