{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook served as the base to test the SageMaker refactored code for this project.\n",
    "\n",
    "What you should know:\n",
    "\n",
    "- During the dev process with SageMaker, we use the `sagemaker` **sdk** to call its functionnalities ( this notebook )\n",
    "- For productionizing, we use SageMaker through API calls via **boto3** ( `sagemaker_hadling/sagemaker.py` via Jenkins )\n",
    "\n",
    "The ML code behind is exactly the same ( meaning the refactored code stays intact ), the only change is *how* we call SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's first set the proxy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HTTP_PROXY'] = \"http://proxy-internet-aws-eu.subsidia.org:3128\"\n",
    "os.environ['HTTPS_PROXY'] = \"http://proxy-internet-aws-eu.subsidia.org:3128\"\n",
    "os.environ['no_proxy'] = \"169.254.169.254,127.0.0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ENV = \"dev\"\n",
    "ONLY_LAST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import src.config as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"../conf/prod.yml\" if RUN_ENV==\"prod\" else \"../conf/dev.yml\"\n",
    "config = cf.ProgramConfiguration(config_file, \"../conf/functional.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Docker images for train & serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.get_train_image_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For dev purposes, when you're working with a notebook instance ( not via Jenkins ), your docker daemon proxies may not have been set right, so run this ( only once for your Notebook instance session ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "sudo su\n",
    "\n",
    "cat <<EOF >> /etc/sysconfig/docker\n",
    "export HTTPS_PROXY=http://proxy-internet-aws-eu.subsidia.org:3128\n",
    "export HTTP_PROXY=http://proxy-internet-aws-eu.subsidia.org:3128\n",
    "export NO_PROXY=169.254.169.254,127.0.0.1\n",
    "EOF\n",
    "\n",
    "service docker restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's build the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, a little something about what happens behind the scenes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The script in charge of building the image is `sagemaker_handling/build_image.sh`.\n",
    "What it does is:\n",
    "\n",
    "- Read the following arguments :\n",
    "`algorithm_name` (the name you'd like to give the Docker image),\n",
    "`run_env` (prod or preprod, it serves as an argument to the Docker image as well, because we need to propagate this variable from this script -running on a SageMaker notebook instance or Jenkins *for prod*- to the machine we pop for learning),\n",
    "`only_last` (True or False, similarly, it serves as an argument to the Docker image)\n",
    "- Update shell proxy variables\n",
    "- Authenticate to ECR ( ForecastUnited account ID )\n",
    "- Builds the image from `sagemaker_handling/Dockerfile_train`\n",
    "- Push the image to ECR\n",
    "\n",
    "**==> You don't have to change this file unless you'd like to change the arguments !**\n",
    "\n",
    "> What happens in `sagemaker_handling/Dockerfile_train` ?\n",
    "\n",
    "Well, we do the following:\n",
    "\n",
    "- Copy the ML source code ( from `src/` and `conf/` ) to `/opt/program` on the Docker container running on the machine we'll pop for ML. Why `/opt/program` ? Because SageMaker expects all source code to be here ( it's a **WORKDIR** is the base Docker images we use, we can change it, but it's better to adhere to the norms ). We also copy the `sagemaker_handling/requirements_train_instance.txt` file to the image.\n",
    "\n",
    "*PS: Any source code you don't COPY will not be available in the Docker image ==> not available in the ML instance machine you'll pop*\n",
    "\n",
    "- We set the arguments ( remember ? `run_env` and `only_last` that we provide when we build the image ) as environment varibles ( in the Docker container on the mmachine we'll pop for ML )\n",
    "\n",
    "- We set a bunch of SageMaker environment variables ( SM_CHANNEL_TRAIN, SM_MODEL_DIR SM_DATA_DIR ), to tell SageMaker where to look for training data and where to put model artefacts.\n",
    "\n",
    "*PS: SageMaker copies your training data from an S3 path you provide ( when you call sagemaker for training - see later on in this notebook `Estimator` class ) to the path *SM_CHANNEL_TRAIN* on the container. So your ML code, should not read data from S3, but from this *local* path ( again, *local* in the container ).\n",
    "\n",
    "- Lastly, we configure the container to run as a Python executable when it's running. What happens is:\n",
    "When SageMaker is called to do training ( **sdk**: `Estimator` or **boto3**: create_training_job() etc. ), it adds an argument called `train` when it runs the Docker image in a container. Since we configured the container to be a Python executable, what happens in the container is:\n",
    "```bash\n",
    "python train\n",
    "```\n",
    "which means that the file in `/opt/program` called `train` ( `/opt/program` in the container, we copied it from *here* `src/train` remember ? ) is executed. This `train` file is where your ML code should be ! More on this later...\n",
    "\n",
    "*PS: We can change the name `train` if we'd like, through a SageMaker environment varibale SM_PROGRAM, but again, the norm is to keep it like this )*\n",
    "\n",
    "**==> You don't have to change this `sagemaker_handling/Dockerfile_train` file if you change your *ML* code ! Unless you want to copy more code in the Docker image, change the arguments, change SageMaker configurations etc.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOW let's build the image !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = config.get_train_image_name()\n",
    "ONLY_LAST_ = str(ONLY_LAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s \"$IMAGE_NAME\" \"$RUN_ENV\" \"$ONLY_LAST_\"\n",
    "\n",
    "cd ..\n",
    "sh sagemaker_handling/build_image.sh $1 $2 $3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = config.get_global_role_arn()\n",
    "image_name = config.get_train_docker_image()\n",
    "bucket = config.get_train_bucket_input()\n",
    "project_id = config.get_train_path_refined_data_input()\n",
    "hyperparameters = config.get_train_hyperparameters()\n",
    "train_instance_count = config.get_train_instance_count()\n",
    "train_instance_type = config.get_train_instance_type()\n",
    "security_group_ids = config.get_global_security_group_ids()\n",
    "subnets = config.get_global_subnets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"- role:\", role,\n",
    "      \"\\n- image name:\", image_name,\n",
    "      \"\\n- bucket:\", bucket,\n",
    "      \"\\n- project_id:\", project_id,\n",
    "      \"\\n- hyperparameters:\\n\", hyperparameters,\n",
    "      \"\\n- train_instance_count:\", train_instance_count,\n",
    "      \"\\n- train_instance_type:\", train_instance_type,\n",
    "      \"\\n- security_group_id:s\", security_group_ids,\n",
    "      \"\\n- subnets:\", subnets\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you'd like to run the docker container locally ( on this SageMaker notebook instance /!\\ careful, it's not a very\n",
    "## powerful instance, training my take a while ) instead of popping a machine ( faster to check your dev for small \n",
    "## datasets ).\n",
    "# If not, let your configured ML instance be ( or change it here if you don't want to change it in the config file )\n",
    "\n",
    "train_instance_type = 'ml.c5.18xlarge' #'local' #'ml.m5.2xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **Estimator** class from SageMaker SDK pops the machine you specify, and runs a container from the Docker image we built ( with the code in it ). This means that it executes the `train` file remember ?\n",
    "SO, for your dev ML, you should only change the `train` file ( of course the file has dependencies with other files, but you know what I mean, the `main` program which runs when you call SageMaker for training is in `train` ). Don't forget to rebuild the image ( i.e. run the `sagemaker_handling/build_image.sh` file EVERYTIME you change the code, you know why ? because the new code needs to be copied to the Docker image )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=train_instance_count,\n",
    "                      train_instance_type=train_instance_type,\n",
    "                      image_name=image_name,\n",
    "                      hyperparameters=hyperparameters,\n",
    "                      security_group_ids=security_group_ids,\n",
    "                      subnets=subnets\n",
    "                      )\n",
    "\n",
    "estimator.fit('s3://' + bucket + '/' + project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module works pretty much like Python's `skopt`. You specify your hyperparameter ranges :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_name = 'demand-forecast-prophet-tuning-dev'# + strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "        'yearly_order': IntegerParameter (26, 29),#, #(1, 30)\n",
    "        'quaterly_order': IntegerParameter(4, 6)#, #(1, 10)   \n",
    "#        'n_changepoints': IntegerParameter(30, 32), #(1, 50)\n",
    "#        'changepoint_range': ContinuousParameter(0.65, 0.69), #(0.6, 1.)\n",
    "#        'changepoint_prior_scale': ContinuousParameter(1.8, 1.9, scaling_type=\"Logarithmic\"), #1e-2, 1e2\n",
    "#        'seasonality_prior_scale': ContinuousParameter(2.2, 2.4, scaling_type=\"Logarithmic\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you must know is that your main training program ( i.e. `train`, you guessed it ! ) should expect the hyperparameters for your ML as program arguments ( this part of the SageMaker code refactoring your must do ).\n",
    "Once you do this, the `HyperparameterTuner` SageMaker module works like magic ! It handles passing different hyperparameter combinations to your main script to test them.\n",
    "\n",
    "But of course, we need to tell the module which hypeparameter combination to choose, i.e. what metric we'd like to optimize ! The way SageMaker does this, is via regular expressions. SO, in your training code, you need to print a metric at some point ( again, part of the SageMaker refactoring you must do ). Then, we tell SageMaker ( via the `HyperparameterTuner` call ) to extract the value of our metric for every combination, then choose the one which achieves our objective type ( i.e. *maximize* or *minimize* )\n",
    "\n",
    "Check out how we did that for this project here:\n",
    "- The function **train_model_fn()** from `src/model.py` ( but in the container its in `/opt/program/model.py`, but you already know that by now if you've ben following ;) ), called through our famous `train` script, does this at the end of training:\n",
    "\n",
    "```python\n",
    "print(\"\\n--------------------------------\\n\")\n",
    "print(\"cutoff_wape:\", str(l_cutoff_wape))\n",
    "print(\"global_wape:\", str(global_wape))\n",
    "print(\"\\n--------------------------------\\n\")\n",
    "```\n",
    "So now, all we have to do is write the right regular expression to extract the **wape** metric we'd like to minimize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'global_wape'\n",
    "objective_type = 'Minimize'\n",
    "metric_definitions = [{'Name': 'global_wape',\n",
    "                       'Regex': 'global_wape: ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=9,\n",
    "                            max_parallel_jobs=1,\n",
    "                            objective_type=objective_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuner.fit({'training': 's3://'+bucket+'/'+project_id,\n",
    "#          'test': 's3://'+bucket+'/'+project_id})\n",
    "\n",
    "tuner.fit('s3://'+bucket+'/'+project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Monitor, in more *visual* details, your tuning job right [here](https://eu-west-1.console.aws.amazon.com/sagemaker/home?region=eu-west-1#/hyper-tuning-jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -----------------------------------------------------------------------------------------------------------------\n",
    " \n",
    " *FbProphet* is too verbose ! This is its output ! Don't be surprised if your notebook gets too slow during training, the prints are too costly ! I did not find a way to reduce the verbosity level, if you do, by all mean, do share and update the code :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=train_instance_count,\n",
    "                      train_instance_type=train_instance_type,\n",
    "                      image_name=image_name,\n",
    "                      hyperparameters=hyperparameters,\n",
    "                      security_group_ids=security_group_ids,\n",
    "                      subnets=subnets\n",
    "                      )\n",
    "\n",
    "estimator.fit('s3://'+bucket+'/'+project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -----------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
