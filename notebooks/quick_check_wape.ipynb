{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import src.utils as ut\n",
    "import src.config as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HTTP_PROXY'] = \"http://proxy-internet-aws-eu.subsidia.org:3128\"\n",
    "os.environ['HTTPS_PROXY'] = \"http://proxy-internet-aws-eu.subsidia.org:3128\"\n",
    "os.environ['no_proxy'] = \"169.254.169.254,127.0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ENV = \"dev\"\n",
    "\n",
    "config_file = \"../conf/prod.yml\" if RUN_ENV==\"prod\" else \"../conf/dev.yml\"\n",
    "config = cf.ProgramConfiguration(config_file, \"../conf/functional.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load active sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_sales = pd.read_parquet('s3://' + config.get_train_bucket_input() + '/' + 'global/active_sales/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_1 = 'Facebook_Prophet'\n",
    "\n",
    "res_files_1 = np.sort([int(re.findall('\\d+', f)[0]) \\\n",
    "                        for f in cutoff_files if f.startswith('Facebook_Prophet_cutoff_') and f[-1].isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_files_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algo_1 = 'Facebook_Prophet_cutoff_'\n",
    "algo_2 = 'APO_Global_Demand'\n",
    "\n",
    "res_files = ut.get_files_list(cf.bucket, cf.s3_path_models_results)\n",
    "res_files_1 = np.array([f for f in res_files if algo_1 in f])\n",
    "res_files_2 = np.array([f for f in res_files if algo_2 in f])\n",
    "\n",
    "res_1 = []\n",
    "res_2 = []\n",
    "\n",
    "for f in res_files_1:\n",
    "    res_1.append(ut.read_csv_S3(cf.bucket, cf.s3_path_models_results + f,  \n",
    "                      parse_dates=['cutoff_date', 'date']))\n",
    "\n",
    "for f in res_files_2:\n",
    "    res_2.append(ut.read_csv_S3(cf.bucket, cf.s3_path_models_results + f,  \n",
    "                      parse_dates=['cutoff_date', 'date']))\n",
    "    \n",
    "res_1 = pd.concat(res_1)\n",
    "res_2 = pd.concat(res_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here from external CSV file\n",
    "#res = pd.read_csv(\"Facebook_Prophet_cutoff_201922.csv\", sep=\"|\", parse_dates=['date'])\n",
    "#res['cutoff_week_id'] = 201922\n",
    "#res['cutoff_date'] = ut.week_id_to_date(res['cutoff_week_id'])\n",
    "#res.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate WAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_1 = pd.merge(res_1, active_sales, how=\"inner\")\n",
    "error_1[\"forecast_step\"] = ((error_1[\"date\"] - error_1[\"cutoff_date\"]) / np.timedelta64(1, 'W')).astype(int) + 1\n",
    "error_1[\"ae\"] = np.abs(error_1[\"yhat\"] - error_1[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_2 = pd.merge(res_2, active_sales, how=\"inner\")\n",
    "error_2[\"forecast_step\"] = ((error_2[\"date\"] - error_2[\"cutoff_date\"]) / np.timedelta64(1, 'W')).astype(int) + 1\n",
    "error_2[\"ae\"] = np.abs(error_2[\"yhat\"] - error_2[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLIK FILTERS : \n",
    "\n",
    "# complete cutoff\n",
    "error_1 = error_1[error_1.cutoff_week_id <= 201947]\n",
    "error_2 = error_2[error_2.cutoff_week_id <= 201947]\n",
    "\n",
    "# models forecasted by algo 1\n",
    "error_2 = pd.merge(error_2, \n",
    "                   error_1[['model', 'cutoff_week_id']].drop_duplicates(), \n",
    "                   how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wape_1 = np.round(error_1[\"ae\"].sum() / error_1[\"y\"].sum() * 100, 3)\n",
    "print(\"Global WAPE \", str(wape_1))\n",
    "print(\"Nb products \", str(error_1.model.unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wape_2 = np.round(error_2[\"ae\"].sum() / error_2[\"y\"].sum() * 100, 3)\n",
    "print(\"Global WAPE \", str(wape_2))\n",
    "print(\"Nb products \", str(error_2.model.unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in np.sort(error_1[\"cutoff_week_id\"].unique()):\n",
    "    error_1_c = error_1[error_1[\"cutoff_week_id\"] == c]\n",
    "    wape = error_1_c[\"ae\"].sum() / error_1_c[\"y\"].sum()\n",
    "    \n",
    "    print(\"Cutoff\", str(c), \":\")\n",
    "    print(\"Nb products \", str(error_1_c.model.unique().shape[0]))\n",
    "    print(\"WAPE:     \", str(wape))\n",
    "    print(\"\\n-------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in np.sort(error_2[\"cutoff_week_id\"].unique()):\n",
    "    error_2_c = error_2[error_2[\"cutoff_week_id\"] == c]\n",
    "    wape = error_2_c[\"ae\"].sum() / error_2_c[\"y\"].sum()\n",
    "    \n",
    "    print(\"Cutoff\", str(c), \":\")\n",
    "    print(\"Nb products \", str(error_2_c.model.unique().shape[0]))\n",
    "    print(\"WAPE:     \", str(wape))\n",
    "    print(\"\\n-------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for s in np.sort(error[\"forecast_step\"].unique()):\n",
    "#    error_s = error[error[\"forecast_step\"] == s]\n",
    "#    wape = error_s[\"ae\"].sum() / error_s[\"y\"].sum()\n",
    "#    \n",
    "#    print(\"Forecast Step\", str(s), \":\")\n",
    "#    print(\"WAPE:     \", str(wape))\n",
    "#    print(\"\\n-------------------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
