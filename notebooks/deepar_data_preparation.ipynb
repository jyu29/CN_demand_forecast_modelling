{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import src.config as cf\n",
    "import src.utils as ut\n",
    "\n",
    "os.environ['HTTP_PROXY'] = \"http://proxy-internet-aws-eu.subsidia.org:3128\"\n",
    "os.environ['HTTPS_PROXY'] = \"http://proxy-internet-aws-eu.subsidia.org:3128\"\n",
    "os.environ['no_proxy'] = \"169.254.169.254,127.0.0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ENV = \"dev\"\n",
    "freq = 'W'\n",
    "prediction_length = 16\n",
    "cutoff_week_id = 201922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"../conf/prod.yml\" if RUN_ENV == \"prod\" else \"../conf/dev.yml\"\n",
    "config = cf.ProgramConfiguration(config_file, \"../conf/functional.yml\")\n",
    "\n",
    "role = config.get_global_role_arn()\n",
    "\n",
    "bucket = config.get_train_bucket_input()\n",
    "prefix = \"test_deepAR\" # Your S3 test dir\n",
    "\n",
    "s3_data_path = \"{}/{}/data\".format(bucket, prefix)\n",
    "s3_output_path = \"{}/{}/output\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Refined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefix = 'specific/full_scope' # To del after data modification\n",
    "\n",
    "train_data_cutoff = ut.read_parquet_S3(\n",
    "    bucket, \"{}/full_scope/train_data_cutoff/train_data_cutoff_{}\".format(prefix, cutoff_week_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data for deepAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_model = train_data_cutoff['model'].sort_values().unique()\n",
    "l_model_test = train_data_cutoff \\\n",
    "    .loc[train_data_cutoff['week_id'] == ut.get_last_week_id(cutoff_week_id),'model'] \\\n",
    "    .sort_values() \\\n",
    "    .unique()\n",
    "\n",
    "nb_ts = l_model.shape[0]\n",
    "cpt = 0\n",
    "\n",
    "train_ts = [] # All time series without the last 16 values\n",
    "val_ts = []   # All time series\n",
    "test_ts = []  # Time series to forecast for futur (=active past week)\n",
    "\n",
    "for m in l_model: # TO OPTIMIZE (parallel? Iterate over groupBy Object?)\n",
    "    ts = train_data_cutoff[train_data_cutoff['model'] == m].set_index('date').asfreq(freq)\n",
    "\n",
    "    train_ts.append(ts[:-prediction_length])\n",
    "    val_ts.append(ts)\n",
    "    if m in l_model_test:\n",
    "        test_ts.append(ts)\n",
    "        \n",
    "    cpt += 1\n",
    "    if cpt % 500 == 0:\n",
    "        print(str(cpt), '/', str(nb_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to S3 in JSONL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_obj(ts, cat=None):\n",
    "    obj = {\"model\": int(ts['model'].values[0]), \n",
    "           \"start\": str(ts.index[0]), \n",
    "           \"target\": list(ts['y'])}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    return obj\n",
    "\n",
    "def series_to_jsonline(ts, cat=None):\n",
    "    return json.dumps(series_to_obj(ts, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "# Train\n",
    "with fs.open(\"{}/cutoff_{}/train.json\".format(s3_data_path, cutoff_week_id), 'wb') as fp:\n",
    "    for ts in train_ts:\n",
    "        fp.write(series_to_jsonline(ts).encode(\"utf-8\"))\n",
    "        fp.write('\\n'.encode(\"utf-8\"))\n",
    "\n",
    "# Val\n",
    "with fs.open(\"{}/cutoff_{}/val.json\".format(s3_data_path, cutoff_week_id), 'wb') as fp:\n",
    "    for ts in val_ts:\n",
    "        fp.write(series_to_jsonline(ts).encode(\"utf-8\"))\n",
    "        fp.write('\\n'.encode(\"utf-8\"))\n",
    "        \n",
    "# Test\n",
    "with fs.open(\"{}/cutoff_{}/test.json\".format(s3_data_path, cutoff_week_id), 'wb') as fp:\n",
    "    for ts in test_ts:\n",
    "        fp.write(series_to_jsonline(ts).encode(\"utf-8\"))\n",
    "        fp.write('\\n'.encode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_forecast-modeling-demand",
   "language": "python",
   "name": "conda_forecast-modeling-demand"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
